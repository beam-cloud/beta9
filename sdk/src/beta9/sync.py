import hashlib
import os
import re
import tempfile
import zipfile
from pathlib import Path
from queue import Queue
from typing import Generator, NamedTuple, Optional, Tuple, Union

from watchdog.events import FileSystemEvent, FileSystemEventHandler

from . import terminal
from .clients.gateway import (
    GatewayServiceStub,
    HeadObjectRequest,
    HeadObjectResponse,
    ObjectMetadata,
    PutObjectRequest,
    PutObjectResponse,
    ReplaceObjectContentOperation,
)
from .config import get_settings
from .env import is_local

_settings = get_settings()

CHUNK_SIZE = 1024 * 1024 * 4
IGNORE_FILE_NAME = f".{_settings.name}ignore".lower()
IGNORE_FILE_CONTENTS = f"""# Generated by {_settings.name} SDK
.{_settings.name.lower()}ignore
.git
.idea
.python-version
.vscode
.venv
venv
*.pyc
__pycache__
.DS_Store
"""


class FileSyncResult(NamedTuple):
    success: bool = False
    object_id: str = ""


class FileSyncer:
    def __init__(
        self,
        gateway_stub: GatewayServiceStub,
        root_dir=".",
    ):
        self.root_dir = Path(root_dir).absolute()
        self.gateway_stub: GatewayServiceStub = gateway_stub

    @property
    def ignore_file_path(self) -> Path:
        return self.root_dir / IGNORE_FILE_NAME

    def _init_ignore_file(self) -> None:
        if not is_local():
            return

        if self.ignore_file_path.exists():
            return

        terminal.detail(f"Writing {IGNORE_FILE_NAME} file")
        with self.ignore_file_path.open(mode="w") as f:
            f.writelines(IGNORE_FILE_CONTENTS)

    def _read_ignore_file(self) -> list:
        if not is_local():
            return []

        terminal.detail(f"Reading {IGNORE_FILE_NAME} file")

        patterns = []

        if self.ignore_file_path.is_file():
            with self.ignore_file_path.open() as file:
                for line in file.readlines():
                    pattern = line.strip()
                    if pattern:
                        regex, include = self._pattern_to_regex(pattern)
                        if include:
                            patterns.append(regex)

        return patterns

    def _should_ignore(self, path: str) -> bool:
        relative_path = os.path.relpath(path, self.root_dir)

        for pattern in self.ignore_patterns:
            if self._match_file(pattern, relative_path):
                return True

        return False

    def _collect_files(self) -> Generator[str, None, None]:
        terminal.detail(f"Collecting files from {self.root_dir}")

        for root, dirs, files in os.walk(self.root_dir):
            dirs[:] = [d for d in dirs if not self._should_ignore(os.path.join(root, d))]

            for file in files:
                file_path = os.path.join(root, file)

                if not self._should_ignore(file_path):
                    yield file_path

    @staticmethod
    def _calculate_sha256(file_path: str, chunk_size: int = CHUNK_SIZE) -> str:
        hasher = hashlib.sha256()
        with open(file_path, "rb") as file:
            while chunk := file.read(chunk_size):
                hasher.update(chunk)
        return hasher.hexdigest()

    # The methods _match_file, _pattern_to_regex, and _translate_segment_glob are copied
    # from pathspec.patterns.gitwildmatch (https://github.com/cpburnz/python-pathspec)
    @staticmethod
    def _match_file(regex: str | bytes, path: str) -> bool:
        match = re.search(regex, path)
        return bool(match)

    def _pattern_to_regex(
        self,
        pattern: Union[str, bytes],
    ) -> Tuple[Optional[Union[str, bytes]], Optional[bool]]:
        _BYTES_ENCODING = "latin1"
        _DIR_MARK = "ps_d"

        if isinstance(pattern, str):
            return_type = str
        elif isinstance(pattern, bytes):
            return_type = bytes
            pattern = pattern.decode(_BYTES_ENCODING)
        else:
            return None, None

        original_pattern = pattern

        if pattern.endswith("\\ "):
            pattern = pattern.lstrip()
        else:
            pattern = pattern.strip()

        if pattern.startswith("#"):
            return None, None

        elif pattern == "/":
            return None, None

        elif pattern:
            if pattern.startswith("!"):
                include = False
                pattern = pattern[1:]
            else:
                include = True

            override_regex = None
            pattern_segs = pattern.split("/")
            is_dir_pattern = not pattern_segs[-1]

            for i in range(len(pattern_segs) - 1, 0, -1):
                prev, seg = pattern_segs[i - 1], pattern_segs[i]
                if prev == "**" and seg == "**":
                    del pattern_segs[i]

            if len(pattern_segs) == 2 and pattern_segs[0] == "**" and not pattern_segs[1]:
                override_regex = f"^.+(?P<{_DIR_MARK}>/).*$"

            if not pattern_segs[0]:
                del pattern_segs[0]
            elif len(pattern_segs) == 1 or (len(pattern_segs) == 2 and not pattern_segs[1]):
                if pattern_segs[0] != "**":
                    pattern_segs.insert(0, "**")

            if not pattern_segs:
                terminal.detail(f"Invalid ignore pattern will be ignored: {original_pattern!r}")

            if not pattern_segs[-1] and len(pattern_segs) > 1:
                pattern_segs[-1] = "**"

            if override_regex is None:
                output = ["^"]
                need_slash = False
                end = len(pattern_segs) - 1
                for i, seg in enumerate(pattern_segs):
                    if seg == "**":
                        if i == 0 and i == end:
                            output.append("[^/]+(?:/.*)?")
                        elif i == 0:
                            output.append("(?:.+/)?")
                            need_slash = False
                        elif i == end:
                            output.append(f"(?P<{_DIR_MARK}>/).*" if is_dir_pattern else "/.*")
                        else:
                            output.append("(?:/.+)?")
                            need_slash = True
                    elif seg == "*":
                        if need_slash:
                            output.append("/")
                        output.append("[^/]+")
                        if i == end:
                            output.append(f"(?:(?P<{_DIR_MARK}>/).*)?")
                        need_slash = True
                    else:
                        if need_slash:
                            output.append("/")
                        output.append(self._translate_segment_glob(seg))
                        if i == end:
                            output.append(f"(?:(?P<{_DIR_MARK}>/).*)?")
                        need_slash = True
                output.append("$")
                regex = "".join(output)
            else:
                regex = override_regex

        else:
            return None, None

        if regex is not None and return_type is bytes:
            regex = regex.encode(_BYTES_ENCODING)

        return regex, include

    @staticmethod
    def _translate_segment_glob(pattern: str) -> str:
        escape = False
        regex = ""
        i, end = 0, len(pattern)
        while i < end:
            char = pattern[i]
            i += 1
            if escape:
                escape = False
                regex += re.escape(char)
            elif char == "\\":
                escape = True
            elif char == "*":
                regex += "[^/]*"
            elif char == "?":
                regex += "[^/]"
            elif char == "[":
                j = i
                if j < end and pattern[j] in "!^":
                    j += 1
                if j < end and pattern[j] == "]":
                    j += 1
                while j < end and pattern[j] != "]":
                    j += 1
                if j < end:
                    j += 1
                    expr = "["
                    if pattern[i] in "!^":
                        expr += "^"
                        i += 1
                    expr += pattern[i:j].replace("\\", "\\\\")
                    regex += expr
                    i = j
                else:
                    regex += "\\["
            else:
                regex += re.escape(char)
        if escape:
            terminal.detail(
                f"Pattern will be ignore because of escape character with no next character: {pattern!r}"
            )
            return ""
        return regex

    def sync(self) -> FileSyncResult:
        terminal.header("Syncing files")

        self._init_ignore_file()
        self.ignore_patterns = self._read_ignore_file()
        temp_zip_name = tempfile.NamedTemporaryFile(delete=False).name

        with zipfile.ZipFile(temp_zip_name, "w") as zipf:
            for file in self._collect_files():
                zipf.write(file, os.path.relpath(file, self.root_dir))
                terminal.detail(f"Added {file}")

        size = os.path.getsize(temp_zip_name)
        hash = self._calculate_sha256(temp_zip_name)

        terminal.detail(f"Collected object is {terminal.humanize_memory(size, base=10)}")

        head_response: HeadObjectResponse = self.gateway_stub.head_object(
            HeadObjectRequest(hash=hash)
        )

        put_response: Optional[PutObjectResponse] = None
        if not head_response.exists:
            metadata = ObjectMetadata(name=hash, size=size)

            def stream_requests():
                with terminal.progress_open(temp_zip_name, "rb", description=None) as file:
                    while chunk := file.read(CHUNK_SIZE):
                        yield PutObjectRequest(chunk, metadata, hash, False)

            terminal.header("Uploading")
            put_response = self.gateway_stub.put_object_stream(stream_requests())

        elif head_response.exists and head_response.ok:
            terminal.header("Files synced")
            return FileSyncResult(success=True, object_id=head_response.object_id)

        os.remove(temp_zip_name)

        if put_response is None or not put_response.ok:
            terminal.error("File sync failed â˜ ï¸")

        terminal.header("Files synced")
        return FileSyncResult(success=True, object_id=put_response.object_id)  # pyright: ignore[reportOptionalMemberAccess]


class SyncEventHandler(FileSystemEventHandler):
    def __init__(self, queue: Queue):
        super().__init__()
        self.queue = queue

    def on_any_event(self, event: FileSystemEvent) -> None:
        if not event.is_directory and event.src_path.endswith(".py"):
            terminal.warn(f"Detected changes in '{event.src_path}'. Reloading...")

    def on_created(self, event) -> None:
        self.queue.put((ReplaceObjectContentOperation.WRITE, event.src_path, None))

    def on_modified(self, event: FileSystemEvent) -> None:
        self.on_created(event)

    def on_deleted(self, event: FileSystemEvent) -> None:
        self.queue.put((ReplaceObjectContentOperation.DELETE, event.src_path, None))

    def on_moved(self, event: FileSystemEvent) -> None:
        self.queue.put((ReplaceObjectContentOperation.MOVED, event.src_path, event.dest_path))
