import asyncio
import fnmatch
import hashlib
import os
import uuid
import zipfile
from pathlib import Path
from queue import Queue
from typing import Generator, NamedTuple, Optional

from watchdog.events import FileSystemEventHandler

from . import terminal
from .clients.gateway import (
    GatewayServiceStub,
    HeadObjectRequest,
    HeadObjectResponse,
    ObjectMetadata,
    PutObjectRequest,
    PutObjectResponse,
    ReplaceObjectContentOperation,
)
from .config import get_settings
from .env import is_local

_settings = get_settings()

CHUNK_SIZE = 1024 * 1024 * 4
IGNORE_FILE_NAME = f".{_settings.name}ignore".lower()
IGNORE_FILE_CONTENTS = f"""# Generated by {_settings.name} SDK
.{_settings.name.lower()}ignore
.git
.idea
.python-version
.vscode
.venv
venv
*.pyc
__pycache__
.DS_Store
"""


class FileSyncResult(NamedTuple):
    success: bool = False
    object_id: str = ""


class FileSyncer:
    def __init__(
        self,
        gateway_stub: GatewayServiceStub,
        root_dir=".",
    ):
        self.loop = asyncio.get_event_loop()
        self.root_dir = Path(root_dir).absolute()
        self.gateway_stub: GatewayServiceStub = gateway_stub

    @property
    def ignore_file_path(self) -> Path:
        return self.root_dir / IGNORE_FILE_NAME

    def _init_ignore_file(self) -> None:
        if not is_local():
            return

        if self.ignore_file_path.exists():
            return

        terminal.detail(f"Writing {IGNORE_FILE_NAME} file")
        with self.ignore_file_path.open(mode="w") as f:
            f.writelines(IGNORE_FILE_CONTENTS)

    def _read_ignore_file(self) -> list:
        if not is_local():
            return []

        terminal.detail(f"Reading {IGNORE_FILE_NAME} file")

        patterns = []

        if self.ignore_file_path.is_file():
            with self.ignore_file_path.open() as file:
                patterns = [line.strip() for line in file.readlines() if line.strip()]

        return patterns

    def _should_ignore(self, path: str) -> bool:
        relative_path = os.path.relpath(path, self.root_dir)

        for pattern in self.ignore_patterns:
            if fnmatch.fnmatch(relative_path, pattern) or fnmatch.fnmatch(
                os.path.basename(path), pattern
            ):
                return True

        return False

    def _collect_files(self) -> Generator[str, None, None]:
        terminal.detail(f"Collecting files from {self.root_dir}")

        for root, dirs, files in os.walk(self.root_dir):
            dirs[:] = [d for d in dirs if not self._should_ignore(os.path.join(root, d))]

            for file in files:
                file_path = os.path.join(root, file)

                if not self._should_ignore(file_path):
                    yield file_path

    @staticmethod
    def _calculate_sha256(file_path: str, chunk_size: int = CHUNK_SIZE) -> str:
        hasher = hashlib.sha256()
        with open(file_path, "rb") as file:
            while chunk := file.read(chunk_size):
                hasher.update(chunk)
        return hasher.hexdigest()

    def sync(self) -> FileSyncResult:
        terminal.header("Syncing files")

        self._init_ignore_file()
        self.ignore_patterns = self._read_ignore_file()
        temp_zip_name = f"/tmp/{uuid.uuid4()}"

        with zipfile.ZipFile(temp_zip_name, "w") as zipf:
            for file in self._collect_files():
                zipf.write(file, os.path.relpath(file, self.root_dir))
                terminal.detail(f"Added {file}")

        size = os.path.getsize(temp_zip_name)
        hash = self._calculate_sha256(temp_zip_name)

        head_response: HeadObjectResponse = self.loop.run_until_complete(
            self.gateway_stub.head_object(HeadObjectRequest(hash=hash))
        )
        put_response: Optional[PutObjectResponse] = None
        if not head_response.exists:
            metadata = ObjectMetadata(name=hash, size=size)

            with terminal.progress("Uploading"):

                def stream_requests():
                    with open(temp_zip_name, "rb") as file:
                        while True:
                            chunk = file.read(CHUNK_SIZE)
                            if not chunk:
                                break
                            yield PutObjectRequest(chunk, metadata, hash, False)

                put_response = self.loop.run_until_complete(
                    self.gateway_stub.put_object_stream(stream_requests())
                )

        elif head_response.exists and head_response.ok:
            terminal.header("Files synced")
            return FileSyncResult(success=True, object_id=head_response.object_id)

        os.remove(temp_zip_name)

        if put_response is None or not put_response.ok:
            terminal.error("File sync failed ☠️")

        terminal.header("Files synced")
        return FileSyncResult(success=True, object_id=put_response.object_id)  # pyright: ignore[reportOptionalMemberAccess]


class SyncEventHandler(FileSystemEventHandler):
    def __init__(self, queue: Queue):
        super().__init__()
        self.queue = queue

    def on_created(self, event):
        if not event.is_directory:
            self.queue.put((ReplaceObjectContentOperation.WRITE, event.src_path))

        terminal.warn(f"File created: {event.src_path}")

    def on_modified(self, event):
        if not event.is_directory:
            self.queue.put((ReplaceObjectContentOperation.WRITE, event.src_path))
            terminal.warn(f"File modified: {event.src_path}")

    def on_deleted(self, event):
        if event.is_directory:
            terminal.warn(f"Folder deleted: {event.src_path}")
        else:
            terminal.warn(f"File deleted: {event.src_path}")

        self.queue.put((ReplaceObjectContentOperation.DELETE, event.src_path))
